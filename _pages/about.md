---
permalink: /
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<h2 id="about-me">About Me</h2>

Hi! I‚Äôm **Shuowen Li (ÊùéÁ°ïÊñá)**, a second-year M.S. student in Optical Engineering at **Tsinghua University**, advised by Prof. Liangcai Cao. I also work as a research intern at the **Academy of Arts & Design**, mentored by Prof. Haipeng Mi. Previously, I received my B.S. in Physics from Lanzhou University, where I studied nanomaterial design under Prof. Hao Jia.

My research focuses on **human‚ÄìAI interaction**, **computational imaging**, and **creative robotics**. I am interested in how intelligent systems can support human creativity by enabling semantic evolution, co-creative storytelling, and generative design. Combining science and art, I build interactive systems that help people create with AI in both digital and physical contexts.

Check out my [CV](../assets/CV_Shuowen_Li.pdf) for more!




<h2 style="font-size: 1.6rem; font-weight: 600; border-bottom: 2px solid #ccc; padding-bottom: 4px; margin-top: 40px;">üìÑ Publications</h2>
<p style="font-size: 0.95rem; color: #666;">(* indicates co-first author)</p>

<ol style="font-size: 0.96rem; line-height: 1.5; padding-left: 1.2em; margin-top: 6px;">
  <li><strong>Shuowen Li</strong>, Kexin Wang, Minglu Fang, Danqi Huang, Ali Asadipour, Haipeng Mi, Yitong Sun. <em>Participatory Evolution of Artificial Life Systems via Semantic Feedback</em>. Submitted to <em>SIGGRAPH Asia 2025 Art Papers</em>. <span style="color: #888;"><em>(Under Review)</em></span></li>
  <li>Ruhan Wang, <strong>Shuowen Li</strong>, Peiran Zhang, Danqi Huang, Yijie Guo, Haipeng Mi. <em>PuppetLine: An Interactive System for Embodied Storytelling with LLM-driven Swarm Robots</em>. Submitted to <em>TEI 2026</em>. <span style="color: #888;"><em>(Under Review)</em></span></li>
  <li>Shihan Qiu<sup>*</sup>, Yuhan Xie<sup>*</sup>, <strong>Shuowen Li</strong><sup>*</sup>, Wei Guo, Xiaoyue Gao, Yijie Guo. <em>Embo: A Wearable Robot Transforming Child-Directed Verbal Aggression into Tactile Feedback</em>. In: <em>ACM/IEEE International Conference on Human-Robot Interaction (HRI '24) Companion</em>, 2024, pp. 857‚Äì861.</li>
  <li><strong>Shuowen Li</strong>, Liangcai Cao. <em>Multidimensional Crosstalk Analysis in Autostereoscopic Displays: Integrating Subjective and Objective Evaluations for Image Quality Assessment</em>. <em>Optics Express</em>, 33(8), 2025, pp. 16911‚Äì16924.</li>
  <li><strong>Shuowen Li</strong>, Yunhui Gao, Jiachen Wu, Mingjie Wang, Zhangcheng Huang, Shumei Chen, Liangcai Cao. <em>Lensless Camera: Unraveling the Breakthroughs and Prospects</em>. <em>Fundamental Research</em>, 2024. <span style="color: #888;"><em>(In Press)</em></span></li>
  <li><strong>Shuowen Li</strong>, Yunhui Gao, Jiachen Wu, Liangcai Cao. <em>Blind Deblurring of Astronomical Images Using SCGTV-Based Single-Frame Method</em>. <em>Optics Express</em>, 32(20), 2024, pp. 35579‚Äì35593.</li>
</ol>




### üìò Book Translation

<div style="display: flex; align-items: flex-start; gap: 16px; margin-top: 10px;">

  <img src="/images/matter_cover.jpg" alt="Matter book cover" style="width: 160px; height: auto; border: 1px solid #ccc;">

  <div>
    <p><em>Geoff Cottrell</em>. <strong><em>Matter: A Very Short Introduction</em></strong>.<br>
    Translated by Xiang Liu, <strong>Shuowen Li</strong>, Jiageng Li.<br>
    Yilin Press, 2024. ISBN: 9787575301671.</p>
    <p><em>A concise yet wide-ranging introduction to matter, guiding readers through its forms from fundamental particles to cosmic structures‚Äîwith clarity and accessibility.</em></p>
  </div>

</div>



## üß™ Projects {#projects}

### üß¨ <strong>Semantic-Guided Artificial Life System</strong>

<div style="display: flex; align-items: flex-start; gap: 16px; margin-top: 10px;">

  <video src="/videos/semantic_life.mp4" autoplay loop muted playsinline style="width: 200px; border-radius: 8px; border: 1px solid #ccc;"></video>

  <div>
    <p>Developed a real-time interactive system where users evolve digital lifeforms using <strong>natural language prompts</strong>. Integrated <strong>CLIP-based multimodal evaluation</strong> and <strong>CMA-ES optimization</strong>, supporting both semantic guidance and emergent swarm behaviors. Enables participatory generative design in the spirit of ‚Äúevolving with intention‚Äù.</p>
  </div>

</div>

### ü§ñ <strong>PuppetLine: Swarm Robotic Storytelling</strong>

<div style="display: flex; align-items: flex-start; gap: 16px; margin-top: 10px;">

  <video src="/videos/toio.mp4" autoplay loop muted playsinline style="width: 200px; border-radius: 8px; border: 1px solid #ccc;"></video>

  <div>
    <p>Built a tangible storytelling system using <strong>Toio robots</strong> and <strong>large language models (LLMs)</strong>. Translates children‚Äôs narrative inputs into synchronized multi-robot actions and emotions. The system empowers <strong>co-creative expression</strong> through embodied interaction.</p>
  </div>

</div>

### ‚úã <strong>Embo: A Wearable Robot for Empathy Education</strong>

<div style="display: flex; align-items: flex-start; gap: 16px; margin-top: 10px;">

  <video src="/videos/embo.mp4" autoplay loop muted playsinline style="width: 200px; border-radius: 8px; border: 1px solid #ccc;"></video>

  <div>
    <p>Designed a wearable puppet robot that transforms <strong>verbal aggression</strong> into <strong>tactile pressure feedback</strong>, addressing bullying scenarios in child‚Äìrobot interaction. Combines <strong>natural language analysis</strong> and <strong>haptic feedback</strong> to build emotional awareness.</p>
  </div>

</div>



### üåå **Astronomical Image Reconstruction**

Developed a GPU-accelerated pipeline for **turbulence removal** in single-frame astronomical images using **blind deconvolution**, **deformable convolution**, and **diffusion models**. Collaborated on hardware‚Äìsoftware co-design with a **four-aperture telescope array**.


### üñºÔ∏è **3D Display Quality Assessment**

Proposed a hybrid evaluation framework for **glasses-free 3D displays**, integrating **optical metrics** and **human visual comfort** analysis. Contributed to drafting **industry standards** for autostereoscopic display technologies.




## üéØ Research Interests {#interests}

* **Human‚ÄìAI Co-Creation**: Designing interactive systems that fuse generative AI with human intention, language, and emotion.
* **Computational Design Tools**: Building tools for evolving, simulating, and editing digital forms‚Äîacross visual, spatial, and behavioral dimensions.
* **Creative Robotics & Embodied Interaction**: Leveraging swarm behavior, wearable tech, and storytelling to create expressive physical interactions.
* **Computational Imaging**: From lensless cameras to astronomical deblurring, exploring inverse problems in optical system design.
* **Visual Perception & Evaluation**: Studying how humans perceive 3D content, depth, and image quality, and modeling this in computational terms.

