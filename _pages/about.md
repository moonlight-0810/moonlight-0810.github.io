---
permalink: /
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hi! I‚Äôm **Shuowen Li (ÊùéÁ°ïÊñá)**, a second-year M.S. student in Optical Engineering at **Tsinghua University**, advised by Prof. Liangcai Cao. I also work as a research intern at the **Academy of Arts & Design**, mentored by Prof. Haipeng Mi. Previously, I received my B.S. in Physics from Lanzhou University, where I studied nanomaterial design under Prof. Hao Jia.

My research focuses on **human‚ÄìAI interaction**, **computational imaging**, and **creative robotics**. I am interested in how intelligent systems can support human creativity by enabling semantic evolution, co-creative storytelling, and generative design. Combining science and art, I build interactive systems that help people create with AI in both digital and physical contexts.

Check out my [CV](../assets/CV_Shuowen_Li.pdf) for more!



<h2 id="projects" style="font-size: 1.6rem; font-weight: 600; border-bottom: 2px solid #ccc; padding-bottom: 4px; margin-top: 40px;">üß™ Projects</h2>

<!-- Project Block -->
<div style="display: flex; gap: 20px; margin-bottom: 30px; padding-bottom: 20px; ">
  <video src="/videos/semantic_life.mp4" autoplay loop muted playsinline style="width: 200px; border-radius: 8px; border: 1px solid #ccc;"></video>
  <div>
    <h3 style="color: #0066cc; margin-top: 0; font-size: 1.25rem;">üß¨ Semantic-Guided Artificial Life System</h3>
    <p style="font-style: italic; font-size: 0.95rem;">
      Developed a real-time interactive system where users evolve digital lifeforms using <strong>natural language prompts</strong>.
      Integrated <strong>CLIP-based multimodal evaluation</strong> and <strong>CMA-ES optimization</strong>, supporting both semantic guidance and emergent swarm behaviors.
      Enables participatory generative design in the spirit of ‚Äúevolving with intention‚Äù.
    </p>
  </div>
</div>

<div style="display: flex; gap: 20px; margin-bottom: 30px; padding-bottom: 20px; ">
  <video src="/videos/toio.mp4" autoplay loop muted playsinline style="width: 200px; border-radius: 8px; border: 1px solid #ccc;"></video>
  <div>
    <h3 style="color: #0066cc; margin-top: 0; font-size: 1.25rem;">ü§ñ PuppetLine: Swarm Robotic Storytelling</h3>
    <p style="font-style: italic; font-size: 0.95rem;">
      Built a tangible storytelling system using <strong>Toio robots</strong> and <strong>large language models (LLMs)</strong>.
      Translates children‚Äôs narrative inputs into synchronized multi-robot actions and emotions.
      The system empowers <strong>co-creative expression</strong> through embodied interaction.
    </p>
  </div>
</div>

<div style="display: flex; gap: 20px; margin-bottom: 30px; padding-bottom: 20px; ">
  <video src="/videos/embo.mp4" autoplay loop muted playsinline style="width: 200px; border-radius: 8px; border: 1px solid #ccc;"></video>
  <div>
    <h3 style="color: #0066cc; margin-top: 0; font-size: 1.25rem;">‚úã Embo: A Wearable Robot for Empathy Education</h3>
    <p style="font-style: italic; font-size: 0.95rem;">
      Designed a wearable puppet robot that transforms <strong>verbal aggression</strong> into <strong>tactile pressure feedback</strong>,
      addressing bullying scenarios in child‚Äìrobot interaction.
      Combines <strong>natural language analysis</strong> and <strong>haptic feedback</strong> to build emotional awareness.
    </p>
  </div>
</div>

<div style="display: flex; gap: 20px; margin-bottom: 30px; padding-bottom: 20px;">
  <video src="/videos/Êú∫Ê¢∞ËáÇ.mp4" autoplay loop muted playsinline style="width: 200px; border-radius: 8px; border: 1px solid #ccc;"></video>
  <div>
    <h3 style="color: #0066cc; margin-top: 0; font-size: 1.25rem;">üñºÔ∏è 3D Display Quality Assessment</h3>
    <p style="font-style: italic; font-size: 0.95rem;">
      Proposed a hybrid evaluation framework for <strong>glasses-free 3D displays</strong>, integrating <strong>optical metrics</strong> and <strong>human visual comfort</strong> analysis.
      Contributed to drafting <strong>industry standards</strong> for autostereoscopic display technologies.
    </p>
  </div>
</div>

<div style="display: flex; gap: 20px; margin-bottom: 30px; padding-bottom: 20px;">
  <img src="/videos/CSST.gif" alt="Astronomical reconstruction" style="width: 200px; border-radius: 8px; border: 1px solid #ccc;">
  <div>
    <h3 style="color: #0066cc; margin-top: 0; font-size: 1.25rem;">üåå Astronomical Image Reconstruction</h3>
    <p style="font-style: italic; font-size: 0.95rem;">
      Developed a GPU-accelerated pipeline for <strong>turbulence removal</strong> in single-frame astronomical images using <strong>blind deconvolution</strong>, <strong>deformable convolution</strong>, and <strong>diffusion models</strong>.
      Collaborated on hardware‚Äìsoftware co-design with a <strong>four-aperture telescope array</strong>.
    </p>
  </div>
</div>



<ol style="font-size: 0.96rem; line-height: 1.5; padding-left: 1.2em; margin-top: 6px;">
  <li><strong>Shuowen Li</strong>, Kexin Wang, Minglu Fang, Danqi Huang, Ali Asadipour, Haipeng Mi, Yitong Sun. 
    <em>Participatory Evolution of Artificial Life Systems via Semantic Feedback</em>. 
    Submitted to <em>SIGGRAPH Asia 2025 Art Papers</em>. 
    <span style="color: #888;"><em>(Under Review)</em></span>
  </li>

  <li>Ruhan Wang, <strong>Shuowen Li</strong>, Peiran Zhang, Danqi Huang, Yijie Guo, Haipeng Mi. 
    <em>PuppetLine: An Interactive System for Embodied Storytelling with LLM-driven Swarm Robots</em>. 
    Submitted to <em>TEI 2026</em>. 
    <span style="color: #888;"><em>(Under Review)</em></span>
  </li>

  <li>Shihan Qiu<sup>*</sup>, Yuhan Xie<sup>*</sup>, <strong>Shuowen Li</strong><sup>*</sup>, Wei Guo, Xiaoyue Gao, Yijie Guo. 
    <em><a href="https://dl.acm.org/doi/abs/10.1145/3610978.3640616" target="_blank" style="color: #0056b3; text-decoration: none;">Embo: A Wearable Robot Transforming Child-Directed Verbal Aggression into Tactile Feedback</a></em>. 
    In: <em>ACM/IEEE International Conference on Human-Robot Interaction (HRI '24) Companion</em>, 2024, pp. 857‚Äì861.
  </li>

  <li><strong>Shuowen Li</strong>, Liangcai Cao. 
    <em><a href="https://opg.optica.org/oe/fulltext.cfm?uri=oe-33-8-16911&id=570059" target="_blank" style="color: #0056b3; text-decoration: none;">Multidimensional Crosstalk Analysis in Autostereoscopic Displays: Integrating Subjective and Objective Evaluations for Image Quality Assessment</a></em>. 
    <em>Optics Express</em>, 33(8), 2025, pp. 16911‚Äì16924.
  </li>

  <li><strong>Shuowen Li</strong>, Yunhui Gao, Jiachen Wu, Mingjie Wang, Zhangcheng Huang, Shumei Chen, Liangcai Cao. 
    <em><a href="https://www.sciencedirect.com/science/article/pii/S2667325824001328" target="_blank" style="color: #0056b3; text-decoration: none;">Lensless Camera: Unraveling the Breakthroughs and Prospects</a></em>. 
    <em>Fundamental Research</em>, 2024. 
    <span style="color: #888;"><em>(In Press)</em></span>
  </li>

  <li><strong>Shuowen Li</strong>, Yunhui Gao, Jiachen Wu, Liangcai Cao. 
    <em><a href="https://opg.optica.org/oe/fulltext.cfm?uri=oe-32-20-35579&id=559910" target="_blank" style="color: #0056b3; text-decoration: none;">Blind Deblurring of Astronomical Images Using SCGTV-Based Single-Frame Method</a></em>. 
    <em>Optics Express</em>, 32(20), 2024, pp. 35579‚Äì35593.
  </li>
</ol>




<h3 style="margin-top: 30px;">üìò Book Translation</h3>

<a href="https://read.douban.com/ebook/479553544/" target="_blank" style="text-decoration: none; color: inherit;">
  <div style="display: flex; align-items: flex-start; gap: 16px; margin-top: 10px;">
    <img src="/images/matter_cover.jpg" alt="Matter book cover" style="width: 160px; height: auto; border: 1px solid #ccc;">
    
    <div>
      <p style="margin: 0;"><em>Geoff Cottrell</em>. <strong><em>Matter: A Very Short Introduction</em></strong>.<br>
      Translated by Xiang Liu, <strong>Shuowen Li</strong>, Jiageng Li.<br>
      Yilin Press, 2024. ISBN: 9787575301671.</p>
      <p style="margin-top: 6px;"><em>A concise yet wide-ranging introduction to matter, guiding readers through its forms from fundamental particles to cosmic structures‚Äîwith clarity and accessibility.</em></p>
    </div>
  </div>
</a>



## üéØ Research Interests {#interests}

* **Human‚ÄìAI Co-Creation**: Designing interactive systems that fuse generative AI with human intention, language, and emotion.
* **Computational Design Tools**: Building tools for evolving, simulating, and editing digital forms‚Äîacross visual, spatial, and behavioral dimensions.
* **Creative Robotics & Embodied Interaction**: Leveraging swarm behavior, wearable tech, and storytelling to create expressive physical interactions.
* **Computational Imaging**: From lensless cameras to astronomical deblurring, exploring inverse problems in optical system design.
* **Visual Perception & Evaluation**: Studying how humans perceive 3D content, depth, and image quality, and modeling this in computational terms.

