---
permalink: /
title: "Shuowen's personal website"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## ğŸ‘‹ About Me

Hi! Iâ€™m **Shuowen Li (æç¡•æ–‡)**, currently a second-year M.S. student in Optical Engineering at the **Department of Precision Instrument, Tsinghua University**, advised by Prof. [Liangcai Cao](https://www.au.tsinghua.edu.cn/info/1133/1413.htm), and collaborating closely with Prof. [Haipeng Mi](https://www.ad.tsinghua.edu.cn/info/1046/1691.htm) at the Academy of Arts & Design.

Iâ€™m broadly interested in **human-AI interaction**, **computational design**, and **creative robotics**. My recent work focuses on bridging intelligent systems and generative interfacesâ€”particularly how we can enable *semantic-driven evolution*, *co-creative storytelling*, and *affective interaction* in digital and physical lifeforms. I enjoy designing interactive systems that integrate AI, simulation, and physical prototyping, with the goal of empowering human creativity through computation.

My technical background spans **optical engineering**, **computational imaging**, and **interactive system design**, including work on lensless imaging, 3D display evaluation, and real-time astronomical image reconstruction. Iâ€™ve published research in *Optics Express*, *Fundamental Research*, and *HRI*, and submitted papers to *SIGGRAPH Asia* and *TEI*.

Check out my [CV](../assets/CV_Shuowen_Li.pdf) for more!





## ğŸ”¥ News

* **2025/01**: Our paper *"Participatory Evolution of Artificial Life Systems via Semantic Feedback"* has been submitted to **SIGGRAPH Asia 2025 Art Papers** ğŸ¨ğŸ§¬
* **2025/01**: Our paper *"PuppetLine: An Interactive System for Embodied Storytelling with LLM-driven Swarm Robots"* has been submitted to **TEI 2026** ğŸ¤–ğŸ“š
* **2024/12**: Our paper *"Multidimensional Crosstalk Analysis in Autostereoscopic Displays"* has been accepted by **Optics Express** ğŸ–¼ï¸ğŸ“
* **2024/08**: Our paper *"Embo: A Wearable Robot Transforming Child-Directed Verbal Aggression into Tactile Feedback"* has been accepted by **HRI 2024 Companion** âœ‹ğŸ§ 
* **2024/07**: Our survey paper *"Lensless Camera: Unraveling the Breakthroughs and Prospects"* is in press at **Fundamental Research** ğŸ§©ğŸ“·
* **2024/06**: Our paper *"Blind Deblurring of Astronomical Images Using SCGTV-Based Single-Frame Method"* has been published in **Optics Express** ğŸŒŒğŸ”­



## ğŸ“„ Publications

### Peer-reviewed Conference Papers

(\* indicates co-first author)

1. **Shihan Qiu\*, Yuhan Xie\*, Shuowen Li\***, Wei Guo, Xiaoyue Gao, Yijie Guo.
   *Embo: A Wearable Robot Transforming Child-Directed Verbal Aggression into Tactile Feedback*.
   In: *ACM/IEEE International Conference on Human-Robot Interaction (HRI '24) Companion*, 2024, pp. 857â€“861.

2. **Shuowen Li\*, Kexin Wang, Minglu Fang, Danqi Huang, Ali Asadipour, Haipeng Mi, Yitong Sun**.
   *Participatory Evolution of Artificial Life Systems via Semantic Feedback*.
   Submitted to *SIGGRAPH Asia 2025 Art Papers*. (*Under Review*)

3. **Ruhan Wang, Shuowen Li, Peiran Zhang, Danqi Huang, Yijie Guo, Haipeng Mi**.
   *PuppetLine: An Interactive System for Embodied Storytelling with LLM-driven Swarm Robots*.
   Submitted to *TEI 2026*. (*Under Review*)



### Journal Papers

4. **Shuowen Li, Liangcai Cao**.
   *Multidimensional Crosstalk Analysis in Autostereoscopic Displays: Integrating Subjective and Objective Evaluations for Image Quality Assessment*.
   *Optics Express*, 33(8), 2025, pp. 16911â€“16924.

5. **Shuowen Li, Yunhui Gao, Jiachen Wu, Mingjie Wang, Zhangcheng Huang, Shumei Chen, Liangcai Cao**.
   *Lensless Camera: Unraveling the Breakthroughs and Prospects*.
   *Fundamental Research*, 2024. (*In Press*)

6. **Shuowen Li, Yunhui Gao, Jiachen Wu, Liangcai Cao**.
   *Blind Deblurring of Astronomical Images Using SCGTV-Based Single-Frame Method*.
   *Optics Express*, 32(20), 2024, pp. 35579â€“35593.



### ğŸ“˜ Book Translation

* Geoff Cottrell. *Matter: A Very Short Introduction*. Translated by **Xiang Liu, Shuowen Li, Jiageng Li**.
  Yilin Press, 2024. ISBN: 9787575301671.




## ğŸ§ª Projects

### ğŸ§¬ **Semantic-Guided Artificial Life System**

*Academy of Arts & Design, Tsinghua University (2023â€“present)*

Developed a real-time interactive system where users evolve digital lifeforms using **natural language prompts**. Integrated **CLIP-based multimodal evaluation** and **CMA-ES optimization**, supporting both semantic guidance and emergent swarm behaviors. Enables participatory generative design in the spirit of "evolving with intention".

### ğŸ¤– **PuppetLine: Swarm Robotic Storytelling**

*Academy of Arts & Design, Tsinghua University (2024â€“present)*

Built a tangible storytelling system using **Toio robots** and **large language models (LLMs)**. Translates childrenâ€™s narrative inputs into synchronized multi-robot actions and emotions. The system empowers **co-creative expression** through embodied interaction.

### âœ‹ **Embo: A Wearable Robot for Empathy Education**

*Academy of Arts & Design, Tsinghua University (2023)*

Designed a wearable puppet robot that transforms **verbal aggression** into **tactile pressure feedback**, addressing bullying scenarios in childâ€“robot interaction. Combines **natural language analysis** and **haptic feedback** to build emotional awareness.

### ğŸŒŒ **Astronomical Image Reconstruction**

*Dept. of Precision Instrument, Tsinghua University (2022â€“2025)*

Developed a GPU-accelerated pipeline for **turbulence removal** in single-frame astronomical images using **blind deconvolution**, **deformable convolution**, and **diffusion models**. Collaborated on hardwareâ€“software co-design with a **four-aperture telescope array**.

### ğŸ–¼ï¸ **3D Display Quality Assessment**

*Dept. of Precision Instrument, Tsinghua University (2022â€“2024)*

Proposed a hybrid evaluation framework for **glasses-free 3D displays**, integrating **optical metrics** and **human visual comfort** analysis. Contributed to drafting **industry standards** for autostereoscopic display technologies.



## ğŸ¯ Research Interests

* **Humanâ€“AI Co-Creation**: Designing interactive systems that fuse generative AI with human intention, language, and emotion.
* **Computational Design Tools**: Building tools for evolving, simulating, and editing digital formsâ€”across visual, spatial, and behavioral dimensions.
* **Creative Robotics & Embodied Interaction**: Leveraging swarm behavior, wearable tech, and storytelling to create expressive physical interactions.
* **Computational Imaging**: From lensless cameras to astronomical deblurring, exploring inverse problems in optical system design.
* **Visual Perception & Evaluation**: Studying how humans perceive 3D content, depth, and image quality, and modeling this in computational terms.

